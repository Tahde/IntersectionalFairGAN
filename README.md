# IntersectionalFairGAN

## Description

This repository implements **IntersectionalFairGAN**, a tool for addressing fairness in machine learning models by considering the intersectionality of sensitive attributes. These codes are based on the paper _"Enhancing Tabular GAN Fairness: The Impact of Intersectional Feature Selection."_ 

We build upon two state-of-the-art GAN models for tabular data generation, **TabFairGAN** and **CTGAN**, modifying the loss function to include an intersectional demographic parity constraint. 

- **TabFairGAN**: Based on Wasserstein GAN, generates synthetic data and applies a demographic parity fairness constraint. We extend this to handle intersectionality, focusing on two sensitive features (e.g., Gender-Age in the Adult dataset).
  
- **CTGAN**: Designed to generate high-quality synthetic tabular data by addressing imbalanced data. We modify CTGAN to include a demographic parity constraint for intersectionality in the generator’s loss function.

## Folder Structure
- `IntersectionTabFair/`: Contains the main scripts, models, and data for analyzing intersectional fairness.
  - `Adult_logs_VIZ.ipynb`: Jupyter notebook for visualizing logs and running analyses.
  - `logs.log`: Log file generated by the process.
  - Other files related to training and testing models.

## Installation
1. Clone the repository:
   ```bash
   git clone https://github.com/Tahde/IntersectionalFairGAN.git


### Running the Project



1. **Train the Model**:
   To train the IntersectionalFairGAN model, use the following script:

   ```bash
   python scripts/train_IntersectionFairGAN.py
   ```

   The training process is split into two phases:
   - **Phase I**: The generator is trained without any fairness constraints by setting λf = 0 (pre-fairness). The general models from this phase are saved in a separate folder called `general_models`.
   - **Phase II**: An intersectional demographic parity constraint is applied. We experiment with λf in the range [0, 2] for TabFairGAN and [0, 1] for CTGAN to identify the best value that balances fairness and fidelity in the learned representations. The models from this phase are saved in the `fairness_models` folder.

   The training process is repeated 10 times for each λf, and metrics such as **accuracy**, **F1 score**, and **demographic parity** are used to evaluate performance. More details on selecting the best λf are provided in the paper's methodology.
   1. **Generate CSV Files**:
   After identifying the best general and fairness models (located in the `best_models` folder), run the following script to generate the CSV files for the Adult dataset:

   ```bash
   python Intersectional-TabFair-Adult-Csv-generator.py
   ```

   This script generates CSV files based on the trained models.

